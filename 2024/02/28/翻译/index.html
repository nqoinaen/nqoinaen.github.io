

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/logo.png">
  <link rel="icon" href="/img/logo.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#2f4154">
  <meta name="author" content="nq0inaen">
  <meta name="keywords" content="">
  
    <meta name="description" content="笔记">
<meta property="og:type" content="article">
<meta property="og:title" content="Joint computation offloading and resource allocation in vehicular edge computing networks">
<meta property="og:url" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/index.html">
<meta property="og:site_name" content="nq0inaen&#39;s blog">
<meta property="og:description" content="笔记">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/4.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/5.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/1.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/2.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/3.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/7-1709029412731.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/8.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/9.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/10.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/6.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/11.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/12.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/13.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/17.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/14.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/15.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/16.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/18.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/19.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/20.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/21.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/22.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/23.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/25.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/26.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/24.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/27.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/28.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/29.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/30.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/31.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/32.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/34.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/37.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/38.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/33.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/35.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/36.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/39.png">
<meta property="og:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/40.png">
<meta property="article:published_time" content="2024-02-28T04:34:32.000Z">
<meta property="article:modified_time" content="2024-02-28T04:51:14.997Z">
<meta property="article:author" content="nq0inaen">
<meta property="article:tag" content="IoV">
<meta property="article:tag" content="VEC">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="https://nqoinaen.github.io/2024/02/28/%E7%BF%BB%E8%AF%91/4.png">
  
  
  
  <title>Joint computation offloading and resource allocation in vehicular edge computing networks - nq0inaen&#39;s blog</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  




  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"nqoinaen.github.io","root":"/","version":"1.9.3","typing":{"enable":false,"typeSpeed":70,"cursorChar":"_","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"left","visible":"hover","icon":""},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":false,"baidu":null,"google":null,"gtag":null,"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml"};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 5.4.2"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>nq0inaen&#39;s blog</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/">
                <i class="iconfont icon-home-fill"></i>
                首页
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/">
                <i class="iconfont icon-archive-fill"></i>
                归档
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/">
                <i class="iconfont icon-category-fill"></i>
                分类
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/">
                <i class="iconfont icon-tags-fill"></i>
                标签
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/">
                <i class="iconfont icon-user-fill"></i>
                关于
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/">
                <i class="iconfont icon-link-fill"></i>
                友链
              </a>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              &nbsp;<i class="iconfont icon-search"></i>&nbsp;
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">&nbsp;<i
                class="iconfont icon-dark" id="color-toggle-icon"></i>&nbsp;</a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/8.png') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.1)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle">Joint computation offloading and resource allocation in vehicular edge computing networks</span>
          
        </div>

        
          
  <div class="mt-3">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-author" aria-hidden="true"></i>
        nq0inaen
      </span>
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-02-28 12:34" pubdate>
          2024年2月28日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          11k 字
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          24 分钟
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <!-- SEO header -->
            <h1 style="display: none">Joint computation offloading and resource allocation in vehicular edge computing networks</h1>
            
              <p class="note note-info">
                
                  
                    本文最后更新于：2024年2月28日 下午
                  
                
              </p>
            
            
              <div class="markdown-body">
                
                <h2 id="车辆边缘计算网络中的联合计算卸载和资源分配">车辆边缘计算网络中的联合计算卸载和资源分配</h2>
<p>Joint computation offloading and resource allocation in vehicular edge<br>
computing networks</p>
<p>关键词： 车辆边缘计算 任务卸载 匹配理论 拉格朗日方法 分布式算法</p>
<h2 id="摘要">摘要</h2>
<p>​	车辆边缘计算（VEC）是一种很有前途的技术，通过将任务卸载到配备边缘计算服务器或邻近车辆的路边单元（RSU）来适应计算密集型和延迟敏感的任务。然而，边缘计算服务器有限的计算资源和车辆的移动性使得卸载策略设计非常具有挑战性。</p>
<p>​	在此背景下，通过考虑车辆移动性带来的潜在传输增益，我们在VEC网络中提出了一种高效的计算卸载和资源分配方案具有两种卸载模式，即车辆到车辆（V2V）和车辆到RSU（ V2R）。我们通过将车辆的卸载延迟、能源消耗和费用与差异化定价策略以及传输增益结合起来，为车辆用户定义了一个新的成本函数。制定优化问题以在延迟和计算能力限制下最小化所有任务车辆的平均成本。<strong>通过将问题解耦为卸载模式选择和资源分配两个子问题，提出了分布式迭代算法。提出了基于匹配理论和基于拉格朗日的算法来分别解决这两个子问题。仿真结果表明，与三种基准方案相比，该算法复杂度较低，系统性能显着提高。</strong></p>
<h2 id="1-介绍">1.介绍</h2>
<p>车联网的出现彻底改变了计算时代，让车辆变得更加智能，为自动驾驶、车载虚拟现实、实时交通监控等计算密集型、时延敏感的应用提供更好的服务与控制[1–3]。然而，车辆有限的计算资源已成为满足智能车辆性能需求的主要瓶颈。车载云计算（VCC）是一种通过将计算任务迁移到远程服务器来应对这一挑战的有效技术，但长距离传输引起的延迟波动降低了卸载效率[4]。为此，车辆边缘计算（VEC）成为一种有前途的技术[5-7]，通过将任务卸载到 VEC 服务器来减轻车辆繁重的计算负担。</p>
<p>任务卸载是 VEC 网络中的一个关键问题。一般来说，车辆生成的计算任务可以卸载到附近配备在路边单元（RSU）中的 VEC 服务器 [8-11]。通常，考虑二元卸载决策问题，其中每个车辆独立地确定是在本地执行任务还是将任务卸载到位于路边的VEC服务器。部分卸载是某些工作中的一种选择，其中输入数据可以动态分为两部分，分别用于本地计算和边缘计算。此外，一些服务车辆可能在一段时间内没有计算任务，因此它们可以通过车对车（V2V）方式出租计算资源来提供计算卸载服务，以换取一些收入[12-15]。 V2V卸载充分利用了部分车辆的闲置计算资源，大大提高了VEC网络的资源利用效率。</p>
<p>然而，随着车辆用户的服务需求增加，有限的边缘服务器资源可能无法同时满足多辆车的需求。此外，车辆的高速移动使得网络拓扑不断变化，可能严重损害通信链路的质量，给卸载策略设计带来严峻的挑战[16]。因此，制定更灵活的联合卸载策略以提高卸载效率非常重要。</p>
<p>为了有效利用车辆和网络边缘的计算资源，设计了涉及V2V和车辆到RSU（V2R）通信模式的各种任务卸载方案，以满足服务质量（QoS）要求[17-20]。然而，现有的研究大多考虑单向车道，忽略了车辆移动的方向性。相比之下，考虑双向双车道场景更为实用。当任务车辆与其选择的VEC服务器之间的距离缩短时，可以实现传输增益，因为数据传输速率随着通信距离变短而增加。据我们所知，现有的工作尚未很好地考虑任务卸载过程中的传输增益。在本文中，我们重点研究能量有限的车辆（例如电动汽车或车载用户设备）的卸载策略，特别是电池容量有限的车辆（例如智能手机和可穿戴设备），其密集计算应用程序不需要不仅有严格的延迟约束，而且还需要大量的计算资源。此外，从绿色通信的角度来看，还需要一种低能耗的卸载方案。因此，应该设计一种有效的任务卸载方案，不仅可以减少任务处理延迟，还可以节省完成卸载任务的能耗。然而，任务卸载并不总能保证低能耗和低延迟，因为卸载数据会增加传输能耗和传输延迟。因此，综合考虑能耗和延迟，设计有效的卸载策略以满足任务车辆的服务质量要求非常重要。受上述事实的启发，我们提出了一种混合任务卸载方案，车辆可以通过选择 V2R 或 V2V 卸载模式自动将任务卸载到 RSU 服务器或服务车辆。考虑到车辆的移动性，通过选择合适的卸载模式并购买一些合理的卸载资源，可以获得更高的服务质量。以最小化所有任务车辆的平均成本为目标，我们联合优化卸载模式选择和计算资源分配。这项工作的<strong>主要贡献</strong>总结如下：</p>
<p><strong>1）我们提出了一种有效的模式选择协议，其中车辆可以在多车辆和多服务器网络中为能量有限的车辆或车载用户设备自主选择V2V或V2R卸载模式。</strong></p>
<p><strong>2）我们考虑车辆的移动性，并定义双向双车道场景中的传输增益，其中传输增益来自于所选服务器与任务车辆之间距离的缩短。此外，RSU服务器和服务车辆采用差异化定价策略，通过向任务车辆出租计算资源来获得收入。</strong></p>
<p><strong>3）我们通过结合任务车辆的卸载延迟、能源消耗、从RSU服务器或服务车辆购买计算资源的费用以及传输增益，设计了一种新颖的车辆成本指标。我们通过联合优化卸载模式选择和计算资源分配，在允许的延迟和计算能力约束下制定平均成本最小化问题。</strong></p>
<p><strong>4）基于匹配理论和拉格朗日对偶理论，我们提出了一种分布式迭代算法来解决原始优化问题，将其分为卸载模式选择子问题和资源分配子问题。仿真结果表明，所提出的算法在复杂度和成本方面大大优于基准方案。</strong></p>
<h2 id="2-相关工作">2.相关工作</h2>
<p>负载任务作为VEC网络中的一个重要问题，目前受到了广泛的研究。加载策略的计算一般可以分为二元加载[8,21]和部分加载[22]。</p>
<ul>
<li>对于二进制卸载，每辆车可以独立决定是在本地计算任务还是将任务卸载到VEC服务器。例如，Nguyen 等人。通过应用二元卸载方案改善车辆服务并减少能源消耗[8]。</li>
<li>对于部分卸载，输入数据被分为两部分，分别用于本地计算和边缘计算。戴等人。提出了联合负载平衡和部分卸载问题以最大化系统效用[22]。参考文献 1 中提出了一种仅依靠 V2V 通信的加载方案的任务。 [18]通过充分利用聚集车辆的闲置资源来执行任务。</li>
</ul>
<p>在上述工作中，车辆通常将其任务卸载到与 RSU 位于同一位置的VEC 服务器。当多辆车辆将任务加载到同一个VEC服务器时，由于VEC服务器的计算能力有限，很难满足车辆用户的延迟QoS要求。如果车辆将任务加载到远程云服务器上，长距离传输将带来沉重的开销。幸运的是，一些具有更强大计算能力的车辆可以充当服务器，承担多车辆和多服务器网络中从相邻车辆加载的任务。例如，张等人。研究了协作加载模式，其中计算资源有限的任务车辆可以将任务加载到提供计算服务的RSU 服务器或服务车辆 [17]。顾等人。使车辆能够将任务卸载给 VEC服务器和具有过多计算资源的车辆 [19]。然而，上述工作没有考虑车辆双向移动性带来的潜在性能增益。**考虑到可用的计算资源和车辆的移动性，我们通过联合考虑 V2R 和 V2V 加载模式以及双向交通中的潜在传输增益，提出了更高效的加载方案。**在这种情况下，任务车辆可以将其任务卸载到 RSU 或附近服务车辆上配备的 VEC 服务器。对于VEC网络中的加载任务，大多数现有工作旨在最小化延迟、能量消耗或费用[9,22-25]。在最大限度地减少延迟方面，Zhang 等人。提出了一种基于软件定义网络（SDN）的负载均衡任务加载方案，以最小化计算任务的处理延迟[23]。然而，更多的文献将延迟和能量消耗一起考虑。李等人。通过构建分层装载模型，共同考虑车辆的延误和成本，以优化装载比例并降低系统消耗[24]。杨等人。共同考虑加载决策、加载时间和计算资源，以最小化通信和计算成本[25]。张等人。联合优化多辆车的卸载比例和上行/计算/下行比特分配，以最小化车辆的总能耗[9]。在上述工作中，仅采用统一定价策略对车辆费用进行建模，即服务器对购买其计算资源的车辆收取相同的单价。在实际应用中，车辆的任务往往不同，车辆与服务器之间的距离也不同。差别定价方案可以获得更大的收入，这使得服务器可以对距离较近的车辆收取更高的价格，从而避免多辆车同时将任务卸载到同一服务器的情况。与现有工作不同的是，我们的目标是通过综合考虑卸载延迟、能源消耗和差别定价费用以及传输增益来最小化所有任务车辆的平均成本。</p>
<h2 id="3-系统模型">3. 系统模型</h2>
<h3 id="3-1车辆边缘网络模型">3.1车辆边缘网络模型</h3>
<p>我们考虑一个具有 M 个 RSU 和 N 个车辆的双向 VEC 网络双车道如图 1 所示，其中 RSU 位于路边。每个 RSU 都配备了一个计算资源有限的 VEC 服务器。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/4.png" srcset="/img/loading.gif" lazyload alt="4"></p>
<p>我们假设每辆车在装载和计算过程中以恒定速度移动。</p>
<p>d i,m(t) 和 d i,j (t) 表示任务车 i 之间的时变距离；</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/5.png" srcset="/img/loading.gif" lazyload alt="5"></p>
<blockquote>
<p>这个是计算i和j之间距离的公式</p>
</blockquote>
<p>其中，h 是 RSU 的高度。</p>
<p>我们考虑信号传播中的大尺度路径损耗和小尺度瑞利衰落效应。由于信道是正交的，相邻车辆之间不存在相互干扰。上行链路传输从 TV i 到 RSU m 的任务率可表示为 r i,m (t) 并由下式给出</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/1.png" srcset="/img/loading.gif" lazyload alt="1"></p>
<blockquote>
<p>δ0为参考距离处大尺度路径损失引起的信道功率增益</p>
<p>H i,m表示 TV i 和 RSU m 之间小尺度瑞利衰落引起的信道增益</p>
<p>κ是路径损耗指数</p>
<p>P是任务车发射功率</p>
<p>σ2为额外噪声的功率</p>
<p>B为信道带宽（B*log应该是）</p>
</blockquote>
<p>类似地，从 TV i 到 SV j 的上行链路传输速率可以表示为 r i,j(t) 并由下式给出</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/2.png" srcset="/img/loading.gif" lazyload alt="2"></p>
<p>定义x i,m 和m作为从 TV i 到 RSU 服务器 m的卸载决策。有如下约束</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/3.png" srcset="/img/loading.gif" lazyload alt="3"></p>
<p>所有TV（任务车）都需要根据自己的业务需求选择合适的加载模式。卸载方式的选择可以直接影响服务器的卸载时延、能耗和费用。接下来我们详细分析以下两种加载模式。</p>
<h3 id="3-2-卸载模型">3.2.卸载模型</h3>
<h4 id="3-2-1-V2R卸载模式">3.2.1. V2R卸载模式</h4>
<p>当TV i决定将其任务卸载到RSU m时，TV i的任务加载延迟可以分为两部分：</p>
<ul>
<li>卸载任务的上行传输时间</li>
<li>卸载任务的计算时间关联的 RSU服务器</li>
</ul>
<p>将t up i;m 表示为将任务从TV i 卸载到RSU 服务器m 的无线传输延迟，</p>
<p>将t exe i;m 表示为计算时间。</p>
<p>给定 TV i 和 RSU 服务器 m 。r i,m 之间的上行传输速率和车辆 i</p>
<p>R i 的任务大小，传输时间t up i;m 可以根据以下方程计算。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/7-1709029412731.png" srcset="/img/loading.gif" lazyload alt="7"></p>
<p>其中 f R i;m 是 RSU 服务器 m 分配给 TV i 的计算资源。由于许多应用的计算输出数据的大小远小于计算输入数据的大小，并且下载数据速率非常高，因此下行链路过程的传输延迟和能量消耗可以忽略不计[26]。因此，V2R 模式的卸载延迟由下式给出</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/8.png" srcset="/img/loading.gif" lazyload alt="8"></p>
<p>类似地，当TV i向RSU服务器m卸载任务时，TV i完成任务的总能耗包括TV i的传输能耗和RSU服务器m的计算能耗。完成电视 i 的任务的总能量成本用 E i,m 表示，可以计算为</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/9.png" srcset="/img/loading.gif" lazyload alt="9"></p>
<p>其中 γ m 是 RSU 服务器 m 的开关电容常数。卸载过程中TV需要购买计算来自 RSU 服务器的资源。我们将μ i,m 表示为价格单位TV i 从 RSU 服务器 m 购买的计算资源。 RSU 服务器 m 收取的TV i 的卸载费用用 e i,m 表示，并由下式给出</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/10.png" srcset="/img/loading.gif" lazyload alt="10"></p>
<h4 id="3-2-2-V2V卸载模式">3.2.2. V2V卸载模式</h4>
<p>当TV i向SV服务器j卸载任务时，TV i的任务加载时延也可以分为两部分：</p>
<ul>
<li>向SV服务器j卸载任务的上行传输时间</li>
<li>SV 服务器 j 的计算时间</li>
</ul>
<p>将t up i;j 表示为将任务从TV i 卸载到SV j 的无线传输时间成本</p>
<p>将t exe i;j 表示为SV 服务器j 处的计算时间。</p>
<p>给定 r i,j 和Ri ，可以通过求解以下方程获得传输时间 t up i;j</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/6.png" srcset="/img/loading.gif" lazyload alt="6"></p>
<p>其中 f S i;j 是分配给 TV i 的 SV j 的计算资源。因此，V2V模式的卸载延迟由下式给出</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/11.png" srcset="/img/loading.gif" lazyload alt="11"></p>
<p>当TV i将任务卸载给SV j时，TV i加载完成任务的能量还包括传输能量和计算能量。 TV i 卸载任务的传输能量成本可以计算为</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/12.png" srcset="/img/loading.gif" lazyload alt="12"></p>
<p>其中 γ j 是 SV j 的开关电容常数。我们将 Delta i,j 表示为SV j 收取的 TV i 计算资源的单价。由于RSU的接入服务是由一些运营商提供的，并且V2V通信总是由移动车辆自组织[13]，因此可以合理地假设V2V加载模式场外计算资源的价格单位远小于V2R加载模式</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/13.png" srcset="/img/loading.gif" lazyload alt="13"></p>
<p>非统一定价机制由VEC服务器（即RSU服务器或SV服务器）应用。这意味着VEC服务器可以向电视收取不同的计算资源单价。这样可以鼓励每台TV选择单价较低的服务器来执行加载任务，以减少购买计算资源的费用。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/17.png" srcset="/img/loading.gif" lazyload alt="17"></p>
<h4 id="3-2-3-传输增益">3.2.3.传输增益</h4>
<p>为了更好地研究传输增益对成本的影响，我们将其视为平均成本的单独部分。当TV加载其当任务分配给逐渐靠近电视的 SV 或 RSU 服务器时，上行链路传输速率将随着电视与其目标服务器之间距离的缩短而增加。存在三种情况：</p>
<ul>
<li>TV 及其选择的 SV 在不同车道上行驶。当TV和选定的 SV 靠近时，它们的距离会变短。</li>
<li>电视及其选择的 SV 在同一车道上行驶。如果TV/SV以较高的速度追赶SV/TV，则TV与SV之间的距离会变短，即快车追慢车。</li>
<li>当TV选择其行驶方向上的前向RSU服务器时，TV与RSU服务器之间的距离也变短。</li>
</ul>
<p>在上述情况下，瞬时传输速率可能远高于全局平均速率，同一时间内可以传输更多的任务。因此，传输增益被定义为以瞬时速率传输的比特数与以平均速率传输的比特数之间的差。我们将 V2R 和 V2V 加载模式下产生的传输增益分别表示为 g i,m 和 g i,j ，分别表示为</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/14.png" srcset="/img/loading.gif" lazyload alt="14"></p>
<p>其中ri;m和ri;j分别表示V2R和V2V加载模式下上行传输的平均速率，即</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/15.png" srcset="/img/loading.gif" lazyload alt="15"></p>
<p>电视倾向于选择距离逐渐缩短的目标VEC服务器，因为缩短的距离可以提高瞬时传输速率和传输增益。需要注意的是，当电视遇到关联的VEC服务器后，它们之间的距离会逐渐增大。在这种情况下，如果任务没有完全卸载，并且瞬时传输速率低于平均传输速率，则累积的传输增益将逐渐被抵消。</p>
<h4 id="3-2-4-成本函数">3.2.4.成本函数</h4>
<p>由于VEC服务器计算资源的限制，当多辆车辆选择同一个VEC服务器来卸载其任务时，卸载策略可能效率较低并导致过载。因此，每辆车应选择合适的卸载模式并购买合适的计算资源，以降低系统成本。我们综合考虑卸载时延和能耗、服务器费用以及传输增益，构建了综合成本函数。电视 i 的成本为</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/16.png" srcset="/img/loading.gif" lazyload alt="16"></p>
<p>其中，ωl和ωe分别表示卸载延迟和卸载的权重能量，分别。 Ti 是完成 TV i 已卸载任务的延迟。 E i 是电视 i 完成卸载任务的总能耗。 e i 是完成 TV i 的卸载任务的费用。它们可以表达如下</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/18.png" srcset="/img/loading.gif" lazyload alt="18"></p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/19.png" srcset="/img/loading.gif" lazyload alt="19"></p>
<h2 id="4-问题表述">4. 问题表述</h2>
<p>我们的目标是通过联合优化卸载关联和计算资源分配来最小化所有电视的总成本。成本最小化问题可以表示为</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/20.png" srcset="/img/loading.gif" lazyload alt="20"></p>
<p>约束C 1 保证任务处理延迟不能超过最大允许延迟T max。</p>
<p>约束C 2 和C 3 确保分配给所有TV的总计算资源不超过RSU服务器或SV的总计算能力。</p>
<p>约束 C 4 、C5 和 C 6 确保每辆车仅将其任务加载给一个 RSU 或 SV。</p>
<p>约束 C 7 确保与同一 SV 关联的 TV 数量不能超过给定阈值 Q。</p>
<p>解决上述优化问题 P 1 的主要难点是整数变量 x i,m 1/4 {0, 1}和 y i,j 1/4 {0, 1} 以及连续变量 f R i;m 和 f S i;j 的相互影响，这使得优化问题 P 1 成为混合整数非线性规划问题，通常是非凸的并且难以在多项式时间内求解[27]。为了解决这个问题，我们将原问题分解为两个子问题，即模式选择子问题和资源分配子问题，然后提出一种低复杂度的分布式迭代算法。</p>
<h2 id="5-建议的解决方案">5. 建议的解决方案</h2>
<p>本节应用匹配理论求解模式选择子问题，应用拉格朗日对偶方法求解资源分配子问题。</p>
<h3 id="5-1-模式选择子问题的求解">5.1.模式选择子问题的求解</h3>
<p>当给定资源分配矩阵F R 和F S 时，P 1 可以变换为</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/21.png" srcset="/img/loading.gif" lazyload alt="21"></p>
<p>在 P 2 中，所有变量 x i,m 、y i,j 都是二元变量，而目标函数相对于 x i,m 和 y i,j 是非线性的。这也是一个整数非线性规划问题。</p>
<p>为了最大限度地降低网络中所有TV的平均成本，那些对计算、通信和延迟要求较高的电视应匹配适当的服务器。匹配理论是研究两组主体之间互利关系形成的一种低复杂度的有用技术[19]。每个代理都有自己的偏好，并使用取决于一些可测量参数的效用函数对相反集合中的代理进行排名。电视根据基于匹配理论生成的偏好列表来做出卸载模式选择的决策，以最小化其成本[28]。此外，匹配决策是由代理本身根据本地收集的信息交互式地做出的。因此，基于匹配理论的协议不需要任何集中协调器，并且可以提高可扩展性。受上述观察的启发，我们提出了一种匹配算法，通过利用电视和 SV 之间的一对一匹配以及 RSU 服务器和电视之间的一对多匹配来查找电视和 VEC 服务器之间的匹配关系。负载模式选择匹配的定义如定义1所示。</p>
<p>定义1.（卸载模式选择匹配）</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/22.png" srcset="/img/loading.gif" lazyload alt="22"></p>
<p>此外，还利用一对一匹配和一对多匹配来解决加载问题的计算。具体来说，电视和SV之间采用一对一匹配，其中一台TV只能将其任务卸载给一台SV，而一台SV只能为一台TV服务。此外，我们在RSU服务器和电视之间应用一对多匹配，其中一台RSU服务器可以为多台TV提供服务。为了解决基于匹配理论的优化问题P 2 ，我们首先需要分别设计TV、RSU服务器和SV的偏好函数和偏好列表。</p>
<h4 id="5-1-1-TV偏好">5.1.1.TV偏好</h4>
<p>为了执行匹配方法，每台TV都需要建立其偏好列表。为了满足QoS 要求，电视更喜欢与可以提供更短延迟、更低能耗和更少费用的RSU 或 SV 关联。由此，我们将卸载时延、能耗、服务器费用、传输增益之和的倒数定义为电视i的偏好函数φT i，得到偏好列表TV i 的 L Ti 按函数值降序排列。 TV i 对 RSU 或 SV 的偏好函数为</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/23.png" srcset="/img/loading.gif" lazyload alt="23"></p>
<h4 id="5-1-2-RSU-或-SV-的偏好">5.1.2. RSU 或 SV 的偏好</h4>
<p>为了获得更高的收入，RSU和SV更愿意接受能够带来更高收入的用户的请求。因此，我们将RSU m 和SV j 的收益作为它们的偏好函数ÏRm 和ÏS j ，并根据函数值的递减顺序确定偏好列表L R m 和LS j 。RSU 服务器 m 和 SV j 对电视的偏好函数如下</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/25.png" srcset="/img/loading.gif" lazyload alt="25"></p>
<p>匹配以迭代方式实现。仍然不匹配的 TV i 将向其最优选的 RSU 服务器和 L T i 中的 SV 发送匹配请求。如果RSU服务器m或SV j仅接收到一个请求，则将构造匹配。如果RSU服务器m或SV j 接收到多个请求，则RSU服务器m和SV j 将反转选择以根据偏好列表L R m 和LS j 构建匹配。已建立匹配关系的 RSU 服务器和 SV 将从所有尚未选择的电视的偏好列表中删除。当所有电视都建立了匹配关系并且没有被任何配对阻挡时，匹配过程将稳定并结束。阻塞对和稳定匹配的定义在下面的定义2和3中给出。</p>
<blockquote>
<p>Definition 2. (blocking pair). TV i and RSU server m or SV j form a blocking pair if both the TV and server prefer the others than their currently matched results.</p>
</blockquote>
<p>如果 TV 和服务器都更喜欢其他结果而不是其当前匹配的结果，则 TV i 和 RSU 服务器 m 或 SV j 相互阻塞。</p>
<blockquote>
<p>Definition 3. (stable matching). A matching Φ is stable if it is not blocked by any pair.</p>
</blockquote>
<h4 id="5-1-3-迭代匹配">5.1.3.迭代匹配</h4>
<p>由于车辆的卸载决策相互影响，所以得到的匹配结果在开始时并不稳定。因此，为了获得稳定的匹配结果，我们采用迭代匹配</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/26.png" srcset="/img/loading.gif" lazyload alt="26"></p>
<p>正如定义 4 中所示，迭代匹配为 TV i 提供了改变其合作伙伴的机会。然而，当且仅当迭代匹配得到服务器认可时，迭代匹配才是有效的，并且当迭代匹配能够提高其效用时，服务器才会认可迭代匹配。迭代匹配与传统匹配的区别主要在于匹配过程中更新偏好列表的方式。具体来说，根据参考文献中所示的匹配理论。 [28]，在传统的匹配算法中，偏好函数在匹配过程中保持不变，并且仅通过删除已经成功匹配的代理来更新偏好列表。对于迭代匹配，如参考文献所示。[30]，偏好函数可以在每轮匹配中更新，然后根据当前匹配结果和资源分配结果重建偏好列表。</p>
<p>现在，我们提出了一种基于匹配理论的模式选择算法来获得最佳匹配策略</p>
<p>Φ*详细信息如算法1所示。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/24.png" srcset="/img/loading.gif" lazyload alt="24"></p>
<h3 id="5-2-资源分配子问题的求解">5.2.资源分配子问题的求解</h3>
<p>当模式选择决策x和y确定后，P 1 可以转化为如下所示的资源分配子问题P 3</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/27.png" srcset="/img/loading.gif" lazyload alt="27"></p>
<blockquote>
<p>定义 5. 假设 f (x)是两次可微的。那么 f（x）是凸的当且仅当 dom f 是凸的并且 f(x) 的 Hessian 矩阵对于所有 x ∈ dom f 都是正半定 (PSD)，即</p>
</blockquote>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/28.png" srcset="/img/loading.gif" lazyload alt="28"></p>
<p>可以证明中的P 3是凸优化问题。</p>
<p>根据定义 5，U i 就变量 f R i;m 和 fS i;j 而言是凹的。另外，由于约束条件C 1 ～C3 也是线性且凸的，因此证明(30)中的P 3是凸优化问题。</p>
<p>仿真参数如下表所示</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/29.png" srcset="/img/loading.gif" lazyload alt="29"></p>
<p>如果原问题是凸问题，则对偶函数的最优解等于其自身的最优解。为了获得低复杂度的等效最优解，采用拉格朗日方法来求解该问题。拉格朗日函数是</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/30.png" srcset="/img/loading.gif" lazyload alt="30"></p>
<p>其中，α、β 和 α 是拉格朗日乘数的向量。这拉格朗日对偶函数由下式给出</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/31.png" srcset="/img/loading.gif" lazyload alt="31"></p>
<p>根据Karush-Kuhn-Tucker（KKT）条件[31]，我们可以得到变量的表达式。我们取 L 对 f R i;m 和 fS i;j 的一阶导数，并令它们等于 0。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/32.png" srcset="/img/loading.gif" lazyload alt="32"></p>
<p>则可得到f R i;m 和f S 的最优解表达式可以根据附录A中给出的(34)~(43)计算。由于拉格朗日函数是可微的，因此拉格朗日乘子的梯度可以得到为</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/34.png" srcset="/img/loading.gif" lazyload alt="34"></p>
<p>其中</p>
<p>Δαi，Δβk，Δρj&gt; 0 是梯度步长，t d 是拉格朗日乘子的迭代次数</p>
<p>拉格朗日方法的详细信息如算法 2 所示</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/37.png" srcset="/img/loading.gif" lazyload alt="37"></p>
<blockquote></blockquote>
<h3 id="5-3-联合模式选择和资源分配优化解决方案">5.3.联合模式选择和资源分配优化解决方案</h3>
<p>为了求解P 1 ，我们提出了一种联合考虑模式选择和资源分配的分布式迭代算法，其总结在算法3中。P 1 可以以分布式方式求解。特别地，我们将 P 1 分解为模式选择和资源分配子问题。首先，基于给定的F R 和F S ，每辆车利用匹配理论获得其模式选择决策X和Y。然后，在得到的模式选择决策下，各车辆利用拉格朗日乘子法求得F R 和F S，重复上述过程直至收敛。整个算法由匹配过程和拉格朗日对偶过程组成。我们将外层循环的迭代次数设置为N 3 ，并将匹配循环和拉格朗日双循环的迭代次数分别设置为N 1 和N 2 。具体来说，在每次内循环迭代中，车辆根据拉格朗日乘数是否收敛的判断标准做出选择决策。当内循环收敛时，外循环开始。匹配过程的复杂性包括以下几个方面：</p>
<p>1）车辆建立偏好列表并发起匹配邀请复杂度为O（I*(J+M)）</p>
<p>2）VEC服务器发起匹配过程，复杂度为O(I+J+M)。因此，匹配过程的复杂度为O(N1(I*(J+M)+(I+J+M)))。拉格朗日过程的<strong>复杂度</strong>主要由<strong>资源分配</strong>和<strong>拉格朗日乘子迭代过程</strong>组成，因此其复杂度为O(N2(I+J+M+I *(J+M)))。因此，对于 N 3 次迭代，我们提出的分布式算法的计算复杂度可以表示为O(N3[(N1(I *(J+M)+(I+J+M)))+(N2(I+J+M+I *(J+M)))])</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/38.png" srcset="/img/loading.gif" lazyload alt="38"></p>
<p>为了在实践中实现所提出的分布式算法，我们使用算法1来确定电视和目标服务器之间的匹配关系，然后使用算法2来确定资源分配。首先，每辆车广播其位置信息并计算车辆之间的距离以更新距离矩阵。由于信道是正交的，车辆之间不存在干扰，只存在高斯白噪声。因此，我们建立了电视和VEC服务器之间的传输速率矩阵。同时，每台电视根据偏好函数建立自己的偏好列表，并向列表中的第一个服务器发送匹配请求。当所有电视发送匹配请求后，如果服务器只收到一个匹配请求，则服务器将与发送他请求的电视形成匹配对。如果一台服务器收到来自多辆车的多个请求，它将选择能够最大化其收入的电视进行匹配。然后，我们使用算法2来确定如何分配资源。两种算法迭代直至收敛。</p>
<h2 id="6-绩效评估">6. 绩效评估</h2>
<h3 id="6-1-模拟设置">6.1.模拟设置</h3>
<p>我们考虑位于双向双车道的车辆网络长度500m。车辆随机分布在该区域。每个SV允许服务的车辆数量阈值是Q×1。表1总结了通信参数。我们考虑计算密集型任务，例如智能导航、道路安全相关交通、娱乐应用等。这些任务对计算资源和处理延迟有不同的要求。我们用 fR i 表示任务的特征； C i ;最大温度</p>
<p>g 分别描述任务数据大小、计算资源需求和截止时间约束。不失一般性，在模拟中，电视的计算任务根据其数据大小、计算资源要求和延迟约束的特点随机分配。具体来说，生成的任务大小在[100, 2000] KB范围内随机分布，计算资源需求在[0.5,10] GHz范围内，最大延迟约束在[0.5, 2.5] s范围内。我们将我们提出的加载方案与以下三个基准方案进行比较：</p>
<ol>
<li>Only V2R模式方案:在TVs上生成的任务全部卸载到最近的RSU服务器上。</li>
</ol>
<p>2）基于距离的选择方案：TV生成的任务可以卸载到RSU服务器或SV，并且仅根据距离选择目标服务器。</p>
<p>3）仅V2V模式方案：TV处生成的任务全部卸载到最近的SV。</p>
<h3 id="6-2-收敛性能">6.2.收敛性能</h3>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/33.png" srcset="/img/loading.gif" lazyload alt="33"></p>
<p>这图是收敛表现：不同的迭代次数时任务车的平均开销</p>
<p>在图2中，所提出方案的收敛性能以网络中不同电视数量（分别为3、5、10和15）下所有电视的平均成本来说明。从图2中，我们可以看到所提出的方案收敛得很快。经过五次或六次迭代后，不同电视数量下所有电视的平均成本很快收敛，这也意味着所提出的算法具有相对较低的复杂度。另外，从图2可以看出，随着电视数量的增加，电视的平均成本也随之增加。原因是所有VEC服务器的计算资源都是有限的。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/35.png" srcset="/img/loading.gif" lazyload alt="35"></p>
<blockquote>
<p>可以看到改进算法比仅 V2V模式的开销是低一点的</p>
</blockquote>
<p>图 3 显示了电视的平均成本与TV数量的关系。为了完成评估，我们在模拟具有 10 个 SV 和 15 个 RSU 服务器的电视的平均成本时选择了不同数量的电视（即 5、10、15、20、25、30、35）。我们可以看到，电视数量越多，电视的平均成本就越高。这是因为，RSU服务器和SV的计算资源是有限的，当电视越多时，分配给每个关联电视的计算资源就越少。此外，我们提出的方案实现的电视平均成本是最低的，这意味着我们提出的方案大大优于现有方案。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/36.png" srcset="/img/loading.gif" lazyload alt="36"></p>
<blockquote>
<p>四种方案下SV数量的影响</p>
</blockquote>
<p>图 4 显示了电视的平均成本与 SV 数量的关系。我们使用 15 台电视和 10 个 RSU 服务器来模拟具有不同数量 SV（即 5、10、15、20、25、30、35）的电视的平均成本。我们可以看到，随着 SV 数量的增加，所有方案的性能都会提高，因为更多的 SV 为电视之间的加载任务提供了更好的机会。相反，SV 的数量对仅 V2R 模式方案的性能影响较小，其中任务全部卸载到 RSU 服务器。给定相同的 SV 集，我们提出的方案的性能比基准方案的性能要好得多。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/39.png" srcset="/img/loading.gif" lazyload alt="39"></p>
<p>图 5 显示了计算 [200,1000] 范围内的每一位所需的 CPU 周期对 10 台电视、5 台电视的平均成本的影响SV 和 5 个 RSU 服务器。当计算每一位所需的 CPU 周期增加时，四种加载方案的电视平均成本也会增加。原因是，电视需要购买更多的计算资源来计算其任务，这会导致更大的延迟、能耗和费用。从曲线变化程度来看，也说明我们的方案具有更好的稳定性。</p>
<p>为了研究延迟权重对电视平均成本的影响，我们模拟了图6中不同权重下的结果。可以看出，在延迟权重下，电视的平均成本随着延迟权重的增加而增加。提出的方案，而曲线的斜率代表全网延迟。相反，基准方案的电视平均成本有所下降。我们提出的方案在不同的时间延迟和能耗权重下始终优于基准方案。我们提出的方案的曲线斜率低于其他基线的曲线斜率，这验证了我们提出的算法的鲁棒性。</p>
<p>此外，我们还在图7中研究了权重变化对延迟和能耗的影响。随着延迟权重的增加，电视的平均延迟降低，电视的平均能耗增加，如图7所示。原因在于，如果电视的延迟权重增大，则延迟对电视平均成本的贡献就越大，并且在车辆成本最小化的情况下，电视的平均延迟呈现下降趋势。能耗权重的降低意味着能耗对电视平均成本的贡献变小，平均能耗呈现增加趋势。此外，电视的低延迟是以能源消耗和负载成本为代价的。本文中，我们设定一个SV只能为一台电视提供加载服务，即Q=1。为了分析Q值的变化对电视平均成本的影响，我们模拟了这种变化当Q &gt; 1时该方案的效果。</p>
<p>图8评估了SV可以服务的最大电视数量对电视平均成本的影响。我们可以观察到电视平均成本呈增加趋势，并且当Q=1时最低。这是因为，当Q的数量增加时，每个SV可以服务的TV数量增加，分配给每个TV的计算资源减少。</p>
<p><img src="/2024/02/28/%E7%BF%BB%E8%AF%91/40.png" srcset="/img/loading.gif" lazyload alt="40"></p>
<p>我们还在图 9(a) 和图 9(b) 中研究了总成本以及延迟、能耗和开销的变化。当Q增加时，所提出方案的平均成本增加，类似于图8。此外，当Q增加时，所提出方案的卸载延迟增加。相反，所提出的方案的卸货能耗和卸货费用减少了。这是因为SV的计算资源是有限的，而TV更愿意花更多的钱购买更多的计算资源来将其任务卸载到RSU服务器。这也是图8中趋势不明显的原因。</p>
<h2 id="7-结论">7.结论</h2>
<p>在本文中，我们联合优化了VEC网络中的负载计算和资源分配，并考虑车辆的移动性提出了一种高效的卸载方案。通过结合考虑模式选择和资源分配以及差异定价，我们的优化问题在计算任务的延迟和计算资源约束下最小化电视的平均成本。通过将问题分解为两个子问题，利用匹配理论解决模式选择子问题，利用拉格朗日方法解决资源分配子问题。最后，我们提出了一种分布式迭代算法来解决原始优化问题。仿真结果证明，与三种基准加载方案相比，我们提出的方案始终能够实现所有TV的平均成本较低。</p>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/%E8%AE%BA%E6%96%87%E7%AC%94%E8%AE%B0/" class="category-chain-item">论文笔记</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/IoV/">#IoV</a>
      
        <a href="/tags/VEC/">#VEC</a>
      
    </div>
  
</div>


              
  

  <div class="license-box my-3">
    <div class="license-title">
      <div>Joint computation offloading and resource allocation in vehicular edge computing networks</div>
      <div>https://nqoinaen.github.io/2024/02/28/翻译/</div>
    </div>
    <div class="license-meta">
      
        <div class="license-meta-item">
          <div>作者</div>
          <div>nq0inaen</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>发布于</div>
          <div>2024年2月28日</div>
        </div>
      
      
        <div class="license-meta-item license-meta-date">
          <div>更新于</div>
          <div>2024年2月28日</div>
        </div>
      
      
        <div class="license-meta-item">
          <div>许可协议</div>
          <div>
            
              
              
                <a target="_blank" href="https://creativecommons.org/licenses/by/4.0/">
                  <span class="hint--top hint--rounded" aria-label="BY - 署名">
                    <i class="iconfont icon-by"></i>
                  </span>
                </a>
              
            
          </div>
        </div>
      
    </div>
    <div class="license-icon iconfont"></div>
  </div>



              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/02/21/%E4%BA%8C%E8%BF%9B%E5%88%B6%E9%9D%A2%E8%AF%95/" title="二进制求职面试">
                        <span class="hidden-mobile">二进制求职面试</span>
                        <span class="visible-mobile">下一篇</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header"><i class="iconfont icon-list"></i>&nbsp;目录</p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  







    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">搜索</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">关键词</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <div style="font-size: 0.85rem">时间慢点走啊</div> <div style="font-size: 0.85rem"> <span id="timeDate">载入天数...</span> <span id="times">载入时分秒...</span> <script src="/js/duration.js"></script> </div> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.0/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>





  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.18.2/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">博客在允许 JavaScript 运行的环境下浏览效果更佳</div>
  </noscript>
</body>
</html>
